"""
ğŸ“ Education Chatbot - Complete RAG System
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

FEATURES:
- Streamlit UI with upload & chat
- 2-Stage RAG (Question Routing)
- Subject Detection (Math, Physics, Chemistry, English)
- Hybrid prompts (context + LLM knowledge)
- Strict mode for document-specific questions

COMPONENTS:
- Embedding: all-MiniLM-L6-v2 (fast)
- Reranker: FlashRank (ONNX)
- LLM: Llama 3.1 8B (4-bit)

RUN: streamlit run app.py

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import streamlit as st
import os
import time
from datetime import datetime

# Page Config
st.set_page_config(
    page_title="Education Chatbot",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS - Dark Theme
st.markdown("""
<style>
    .status-pending { color: #FFA500; font-weight: bold; }
    .status-processing { color: #00BFFF; font-weight: bold; }
    .status-completed { color: #00FF7F; font-weight: bold; }
    .status-error { color: #FF6B6B; font-weight: bold; }
    .file-card {
        padding: 12px 15px;
        border-radius: 10px;
        margin: 8px 0;
        background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
        border: 1px solid #0f3460;
        color: #e0e0e0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
    }
    .file-card b { color: #00d4ff; }
    .file-card small { color: #a0a0a0; }
    .stats-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 15px;
        border-radius: 10px;
        color: white;
        text-align: center;
    }
    .mode-badge {
        display: inline-block;
        padding: 4px 12px;
        border-radius: 12px;
        font-size: 0.85em;
        font-weight: bold;
    }
    .mode-hybrid {
        background: linear-gradient(135deg, #00d4ff, #0099cc);
        color: white;
    }
    .mode-strict {
        background: linear-gradient(135deg, #ff6b6b, #ee5a5a);
        color: white;
    }
    .mode-llm {
        background: linear-gradient(135deg, #ffd700, #ffb700);
        color: #333;
    }
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #0f0f1a 0%, #1a1a2e 100%);
    }
    [data-testid="stSidebar"] .stMarkdown {
        color: #e0e0e0;
    }
</style>
""", unsafe_allow_html=True)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INITIALIZE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
UPLOADS_DIR = "./uploads"
DATA_DIR = "./data"
os.makedirs(UPLOADS_DIR, exist_ok=True)
os.makedirs(DATA_DIR, exist_ok=True)

# Session State
if "messages" not in st.session_state:
    st.session_state.messages = []

if "file_status" not in st.session_state:
    st.session_state.file_status = {}

if "models_loaded" not in st.session_state:
    st.session_state.models_loaded = False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LOAD MODELS (Cached)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@st.cache_resource(show_spinner=False)
def load_rag_engine():
    """Load RAG Hybrid Engine"""
    from rag_engine import RAGHybrid
    return RAGHybrid()


@st.cache_resource(show_spinner=False)
def load_prompts():
    """Load prompt functions"""
    from prompts import detect_subject, get_subject_emoji, get_subject_name
    return {
        "detect_subject": detect_subject,
        "get_subject_emoji": get_subject_emoji,
        "get_subject_name": get_subject_name
    }


@st.cache_resource(show_spinner=False)
def load_utils():
    """Load utility functions"""
    from utils import route_language, contains_cjk, clean_response
    return {
        "route_language": route_language,
        "contains_cjk": contains_cjk, 
        "clean_response": clean_response
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SIDEBAR - File Upload & Status
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with st.sidebar:
    st.title("ğŸ“ Education Chatbot")
    st.caption("2-Stage RAG vá»›i Question Routing")
    
    st.markdown("---")
    
    # Model Loading Status
    st.markdown("### ğŸ”§ Tráº¡ng thÃ¡i há»‡ thá»‘ng")
    
    if not st.session_state.models_loaded:
        with st.spinner("Äang táº£i models..."):
            try:
                rag = load_rag_engine()
                prompts = load_prompts()
                utils = load_utils()
                
                # Preload models
                rag.preload_lite()
                
                st.session_state.models_loaded = True
                st.success("âœ… Há»‡ thá»‘ng sáºµn sÃ ng!")
            except Exception as e:
                st.error(f"âŒ Lá»—i: {e}")
                st.stop()
    else:
        rag = load_rag_engine()
        prompts = load_prompts()
        utils = load_utils()
        st.success("âœ… Há»‡ thá»‘ng sáºµn sÃ ng!")
    
    # Stats
    stats = rag.get_stats()
    col1, col2 = st.columns(2)
    with col1:
        st.metric("ğŸ“ Files", stats['files'])
    with col2:
        st.metric("ğŸ“¦ Chunks", stats['chunks'])
    
    st.markdown("---")
    
    # File Upload
    st.markdown("### ğŸ“¤ Upload tÃ i liá»‡u")
    uploaded_files = st.file_uploader(
        "KÃ©o tháº£ hoáº·c chá»n files",
        type=["pdf", "txt", "md", "csv"],
        accept_multiple_files=True,
        key="file_uploader"
    )
    
    # Process uploaded files
    if uploaded_files:
        new_files = []
        for file in uploaded_files:
            if file.name not in st.session_state.file_status:
                new_files.append(file)
        
        if new_files:
            st.markdown("#### ğŸ”„ Äang xá»­ lÃ½...")
            progress_bar = st.progress(0)
            
            for i, file in enumerate(new_files):
                st.session_state.file_status[file.name] = {
                    "status": "processing",
                    "chunks": 0,
                    "time": None
                }
                
                # Save file
                filepath = os.path.join(UPLOADS_DIR, file.name)
                with open(filepath, "wb") as f:
                    f.write(file.getbuffer())
                
                # Process
                try:
                    start_time = time.time()
                    chunks = rag.index_file(filepath, file.name)
                    elapsed = time.time() - start_time
                    
                    st.session_state.file_status[file.name] = {
                        "status": "completed",
                        "chunks": chunks,
                        "time": f"{elapsed:.1f}s"
                    }
                except Exception as e:
                    st.session_state.file_status[file.name] = {
                        "status": "error",
                        "error": str(e)
                    }
                
                progress_bar.progress((i + 1) / len(new_files))
            
            progress_bar.empty()
            st.rerun()
    
    # File Status List
    if st.session_state.file_status:
        st.markdown("#### ğŸ“‹ Danh sÃ¡ch tÃ i liá»‡u")
        
        for filename, info in st.session_state.file_status.items():
            status = info.get("status", "pending")
            
            if status == "completed":
                chunks = info.get('chunks', 0)
                time_taken = info.get('time', '')
                st.markdown(f"""
                <div class="file-card">
                    âœ… <b>{filename}</b><br/>
                    <small>ğŸ“¦ {chunks} chunks | â±ï¸ {time_taken}</small>
                </div>
                """, unsafe_allow_html=True)
            elif status == "processing":
                st.markdown(f"""
                <div class="file-card">
                    ğŸ”„ <b>{filename}</b><br/>
                    <small class="status-processing">Äang xá»­ lÃ½...</small>
                </div>
                """, unsafe_allow_html=True)
            elif status == "error":
                error = info.get('error', 'Unknown error')
                st.markdown(f"""
                <div class="file-card">
                    âŒ <b>{filename}</b><br/>
                    <small class="status-error">{error[:50]}</small>
                </div>
                """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Clear buttons
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ—‘ï¸ XÃ³a chat"):
            st.session_state.messages = []
            st.rerun()
    with col2:
        if st.button("ğŸ”„ Refresh"):
            st.rerun()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN CHAT INTERFACE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.title("ğŸ’¬ Há»i Ä‘Ã¡p ThÃ´ng minh")

# Instructions
if not st.session_state.file_status:
    st.info("""
    ğŸ“ **Education Chatbot - 2-Stage RAG System**
    
    **Báº¡n cÃ³ thá»ƒ há»i ngay!** KhÃ´ng cáº§n upload tÃ i liá»‡u.
    
    **Há»‡ thá»‘ng tá»± Ä‘á»™ng chá»n mode:**
    - âš¡ **Fast Mode**: CÃ¢u há»i chung â†’ RAG Lite + LLM General Knowledge
    - ğŸ“š **Deep Mode**: "Theo tÃ i liá»‡u...", "Trong sÃ¡ch..." â†’ RAG Pro (strict)
    
    **MÃ´n há»c há»— trá»£:**
    ğŸ”¢ ToÃ¡n há»c | âš›ï¸ Váº­t lÃ½ | ğŸ§ª HÃ³a há»c | ğŸ”¤ Tiáº¿ng Anh
    """)

# Display chat history
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Chat input
if user_input := st.chat_input("Nháº­p cÃ¢u há»i..."):
    # Display user message
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # Analyze question
    detect_subject = prompts["detect_subject"]
    get_subject_emoji = prompts["get_subject_emoji"]
    get_subject_name = prompts["get_subject_name"]
    route_language = utils["route_language"]
    
    subject = detect_subject(user_input)
    language = route_language(user_input)
    subject_emoji = get_subject_emoji(subject)
    subject_name = get_subject_name(subject, language)
    
    # Show detection info
    st.markdown(f"""
    <div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); 
                padding: 10px 15px; border-radius: 8px; margin: 10px 0;
                border-left: 4px solid #00d4ff;">
        {subject_emoji} <b>MÃ´n há»c:</b> {subject_name} | 
        ğŸŒ <b>NgÃ´n ngá»¯:</b> {"Tiáº¿ng Viá»‡t" if language == "vi" else "English"}
    </div>
    """, unsafe_allow_html=True)
    
    # Generate response
    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        
        try:
            with st.spinner("ğŸ” Äang xá»­ lÃ½..."):
                # Query with routing
                answer, mode = rag.query_with_mode(user_input)
                
                # Show mode indicator
                if mode == "rag_lite":
                    mode_html = '<span class="mode-badge mode-hybrid">âš¡ Hybrid Mode</span>'
                elif mode == "rag_pro":
                    mode_html = '<span class="mode-badge mode-strict">ğŸ“š Strict Mode</span>'
                else:
                    mode_html = '<span class="mode-badge mode-llm">ğŸ¤– LLM Only</span>'
                
                st.markdown(mode_html, unsafe_allow_html=True)
                response_placeholder.markdown(answer)
                
        except Exception as e:
            answer = f"âŒ Lá»—i khi xá»­ lÃ½: {e}"
            response_placeholder.markdown(answer)
        
        # Save assistant message
        st.session_state.messages.append({"role": "assistant", "content": answer})


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FOOTER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.markdown("---")
st.caption("""
ğŸ“ **Education Chatbot** | Powered by 2-Stage RAG + Llama 3.1 8B  
âš¡ Fast: MiniLM + FlashRank | ğŸ“š Deep: BGE-M3 + Reranker
""")

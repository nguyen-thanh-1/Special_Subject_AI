"""
PageIndex-inspired RAG System with Llama 3.1 8B
S·ª≠ d·ª•ng LLM t·ª´ file Llama_3_1_8B_Instruct_v2.py
"""

import sys
from pathlib import Path
import importlib.util

# Import LLM module t·ª´ file c√≥ s·∫µn
def import_llm_module():
    """Import module Llama t·ª´ file c√≥ s·∫µn"""
    module_path = Path(__file__).parent / "Llama_3_1_8B_Instruct_v2.py"
    
    spec = importlib.util.spec_from_file_location("llama_module", module_path)
    llama_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(llama_module)
    
    return llama_module

# Load LLM
print("ƒêang import Llama 3.1 8B model...")
llama = import_llm_module()
print("Model ƒë√£ s·∫µn s√†ng!")

# ==================== PageIndex Implementation ====================
class LocalPageIndex:
    """
    Local implementation c·ªßa PageIndex - Tree-structured document indexing
    Kh√¥ng c·∫ßn vector database, s·ª≠ d·ª•ng c·∫•u tr√∫c ph√¢n c·∫•p t·ª± nhi√™n
    """
    
    def __init__(self, documents_dir="./courses"):
        self.documents_dir = Path(documents_dir)
        self.index = {}
        self.documents = {}
        
    def build_index(self):
        """X√¢y d·ª±ng index ph√¢n c·∫•p t·ª´ t√†i li·ªáu"""
        print(f"\nüìö ƒêang x√¢y d·ª±ng PageIndex t·ª´ {self.documents_dir}...")
        
        if not self.documents_dir.exists():
            print(f"‚ö†Ô∏è  T·∫°o th∆∞ m·ª•c: {self.documents_dir}")
            self.documents_dir.mkdir(parents=True, exist_ok=True)
            return
        
        # X·ª≠ l√Ω t·∫•t c·∫£ file .txt
        txt_files = list(self.documents_dir.glob("*.txt"))
        
        if not txt_files:
            print(f"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y file .txt n√†o trong {self.documents_dir}")
            return
        
        for file_path in txt_files:
            self._index_document(file_path)
        
        print(f"‚úÖ ƒê√£ index {len(self.documents)} t√†i li·ªáu v·ªõi {sum(len(d['sections']) for d in self.documents.values())} sections")
        
    def _index_document(self, file_path):
        """Index m·ªôt t√†i li·ªáu v·ªõi c·∫•u tr√∫c ph√¢n c·∫•p"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            print(f"‚ö†Ô∏è  L·ªói ƒë·ªçc file {file_path}: {e}")
            return
        
        doc_name = file_path.stem
        
        # T√°ch t√†i li·ªáu th√†nh sections (theo ƒëo·∫°n vƒÉn)
        sections = [s.strip() for s in content.split('\n\n') if s.strip()]
        
        # T·∫°o c·∫•u tr√∫c ph√¢n c·∫•p
        doc_structure = {
            'name': doc_name,
            'path': str(file_path),
            'sections': []
        }
        
        for idx, section in enumerate(sections):
            # X√°c ƒë·ªãnh ti√™u ƒë·ªÅ (d√≤ng ƒë·∫ßu ti√™n n·∫øu ng·∫Øn ho·∫∑c k·∫øt th√∫c b·∫±ng :)
            lines = section.split('\n')
            if len(lines) > 1 and (lines[0].endswith(':') or len(lines[0]) < 100):
                title = lines[0].strip(':').strip()
                content_text = '\n'.join(lines[1:]).strip()
            else:
                title = f"Ph·∫ßn {idx + 1}"
                content_text = section
            
            doc_structure['sections'].append({
                'title': title,
                'content': content_text,
                'index': idx
            })
        
        self.documents[doc_name] = doc_structure
        self.index[doc_name] = {
            'sections': [s['title'] for s in doc_structure['sections']],
            'path': str(file_path)
        }
        
        print(f"  üìÑ {doc_name}: {len(doc_structure['sections'])} sections")
    
    def search(self, query, top_k=3):
        """
        T√¨m ki·∫øm sections li√™n quan s·ª≠ d·ª•ng reasoning
        Tr·∫£ v·ªÅ c√°c sections li√™n quan nh·∫•t
        """
        if not self.documents:
            return []
        
        relevant_sections = []
        
        for doc_name, doc_data in self.documents.items():
            for section in doc_data['sections']:
                # T√≠nh ƒëi·ªÉm li√™n quan
                score = self._calculate_relevance(query, section['title'], section['content'])
                
                if score > 0:
                    relevant_sections.append({
                        'document': doc_name,
                        'title': section['title'],
                        'content': section['content'],
                        'score': score
                    })
        
        # S·∫Øp x·∫øp theo ƒëi·ªÉm v√† l·∫•y top_k
        relevant_sections.sort(key=lambda x: x['score'], reverse=True)
        return relevant_sections[:top_k]
    
    def _calculate_relevance(self, query, title, content):
        """T√≠nh ƒëi·ªÉm li√™n quan ƒë∆°n gi·∫£n (c√≥ th·ªÉ n√¢ng c·∫•p v·ªõi LLM)"""
        query_lower = query.lower()
        title_lower = title.lower()
        content_lower = content.lower()
        
        score = 0
        
        # T√¨m c√°c t·ª´ kh√≥a trong query
        query_terms = [term for term in query_lower.split() if len(term) > 2]
        
        for term in query_terms:
            # Ti√™u ƒë·ªÅ c√≥ tr·ªçng s·ªë cao h∆°n
            if term in title_lower:
                score += 5
            # N·ªôi dung c√≥ tr·ªçng s·ªë th·∫•p h∆°n
            if term in content_lower:
                score += 1
        
        return score
    
    def get_context(self, query, max_sections=3):
        """L·∫•y context ƒë√£ format cho LLM prompt"""
        sections = self.search(query, top_k=max_sections)
        
        if not sections:
            return None, []
        
        context_parts = []
        sources = []
        
        for section in sections:
            context_parts.append(
                f"üìñ [{section['document']}] - {section['title']}\n{section['content']}"
            )
            sources.append(f"{section['document']} - {section['title']}")
        
        context = "\n\n" + "="*60 + "\n\n".join(context_parts)
        
        return context, sources


# ==================== RAG System ====================
class PageIndexRAG:
    """RAG system k·∫øt h·ª£p LocalPageIndex v·ªõi Llama 3.1 8B"""
    
    def __init__(self, documents_dir="./courses"):
        self.page_index = LocalPageIndex(documents_dir)
        self.page_index.build_index()
        
        self.system_prompt = """B·∫°n l√† m·ªôt tr·ª£ l√Ω AI gi√°o d·ª•c th√¥ng minh v√† chuy√™n nghi·ªáp.

NHI·ªÜM V·ª§:
- Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin t·ª´ t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p
- Gi·∫£i th√≠ch r√µ r√†ng, chi ti·∫øt v√† c√≥ c·∫•u tr√∫c
- S·ª≠ d·ª•ng v√≠ d·ª• c·ª• th·ªÉ khi c·∫ßn thi·∫øt

QUY T·∫ÆC B·∫ÆT BU·ªòC:
1. Tr·∫£ l·ªùi HO√ÄN TO√ÄN b·∫±ng ti·∫øng Vi·ªát
2. D·ª±a v√†o th√¥ng tin trong t√†i li·ªáu ƒë·ªÉ tr·∫£ l·ªùi
3. N·∫øu th√¥ng tin kh√¥ng c√≥ trong t√†i li·ªáu, h√£y n√≥i r√µ "Th√¥ng tin n√†y kh√¥ng c√≥ trong t√†i li·ªáu"
4. Tr√≠ch d·∫´n ngu·ªìn khi c·∫ßn thi·∫øt
5. Tr·∫£ l·ªùi ng·∫Øn g·ªçn nh∆∞ng ƒë·∫ßy ƒë·ªß √Ω
"""
    
    def query(self, question, max_new_tokens=512, temperature=0.2):
        """
        Truy v·∫•n h·ªá th·ªëng RAG
        
        Args:
            question: C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
            max_new_tokens: S·ªë token t·ªëi ƒëa ƒë·ªÉ sinh
            temperature: Nhi·ªát ƒë·ªô sampling
            
        Returns:
            response: C√¢u tr·∫£ l·ªùi
            sources: Danh s√°ch ngu·ªìn tham kh·∫£o
        """
        # L·∫•y context t·ª´ PageIndex
        context, sources = self.page_index.get_context(question, max_sections=3)
        
        if context is None:
            return "‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong t√†i li·ªáu. Vui l√≤ng th√™m t√†i li·ªáu ho·∫∑c h·ªèi c√¢u h·ªèi kh√°c.", []
        
        # X√¢y d·ª±ng prompt v·ªõi context
        user_prompt = f"""D·ª±a v√†o c√°c th√¥ng tin sau t·ª´ t√†i li·ªáu:

{context}

{'='*60}

C√¢u h·ªèi: {question}

H√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin trong t√†i li·ªáu ·ªü tr√™n. N·∫øu c·∫ßn, h√£y t·ªïng h·ª£p t·ª´ nhi·ªÅu ngu·ªìn."""
        
        # T·∫°o history v·ªõi system prompt
        history = [
            {"role": "system", "content": self.system_prompt}
        ]
        
        # G·ªçi LLM
        try:
            response = llama.generate_response(
                user_input=user_prompt,
                history=history,
                max_new_tokens=max_new_tokens,
                temperature=temperature
            )
            
            return response.strip(), sources
            
        except Exception as e:
            return f"‚ùå L·ªói khi sinh c√¢u tr·∫£ l·ªùi: {e}", []
    
    def rebuild_index(self):
        """X√¢y d·ª±ng l·∫°i index (khi c√≥ t√†i li·ªáu m·ªõi)"""
        print("\nüîÑ ƒêang x√¢y d·ª±ng l·∫°i index...")
        self.page_index = LocalPageIndex(self.page_index.documents_dir)
        self.page_index.build_index()


# ==================== Interactive Interface ====================
def main():
    print("=" * 70)
    print("üöÄ PageIndex + Llama 3.1 8B RAG System")
    print("=" * 70)
    print("\nüìå ƒê·∫∑c ƒëi·ªÉm c·ªßa PageIndex:")
    print("  ‚úÖ Kh√¥ng s·ª≠ d·ª•ng vector database")
    print("  ‚úÖ C·∫•u tr√∫c c√¢y ph√¢n c·∫•p t·ª± nhi√™n")
    print("  ‚úÖ Reasoning-based retrieval")
    print("  ‚úÖ B·∫£o to√†n ng·ªØ c·∫£nh t√†i li·ªáu")
    print("=" * 70)
    
    # Kh·ªüi t·∫°o RAG system
    rag = PageIndexRAG(documents_dir="./courses")
    
    print("\n‚úÖ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!")
    print("\nüìù L·ªánh ƒë·∫∑c bi·ªát:")
    print("  ‚Ä¢ 'rebuild' - X√¢y d·ª±ng l·∫°i index t·ª´ t√†i li·ªáu")
    print("  ‚Ä¢ 'exit' ho·∫∑c 'quit' - Tho√°t ch∆∞∆°ng tr√¨nh")
    print("=" * 70)
    
    while True:
        print("\n")
        user_input = input("üí¨ C√¢u h·ªèi c·ªßa b·∫°n: ").strip()
        
        if not user_input:
            continue
        
        if user_input.lower() in ["exit", "quit"]:
            print("\nüëã T·∫°m bi·ªát!")
            break
        
        if user_input.lower() == "rebuild":
            rag.rebuild_index()
            continue
        
        print("\nü§ñ ƒêang x·ª≠ l√Ω...")
        print("=" * 70)
        
        try:
            response, sources = rag.query(user_input)
            
            print("\nüìù Tr·∫£ l·ªùi:")
            print(response)
            
            if sources:
                print("\nüìö Ngu·ªìn tham kh·∫£o:")
                for idx, source in enumerate(sources, 1):
                    print(f"  {idx}. {source}")
            
        except Exception as e:
            print(f"\n‚ùå L·ªói: {e}")
            import traceback
            traceback.print_exc()
        
        print("=" * 70)


if __name__ == "__main__":
    main()

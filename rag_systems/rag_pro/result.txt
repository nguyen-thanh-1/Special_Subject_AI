PS C:\Users\Admin\Desktop\Special_Subject_AI> & c:/Users/Admin/Desktop/Special_Subject_AI/.venv/Scripts/Activate.ps1
(special-subject-ai) PS C:\Users\Admin\Desktop\Special_Subject_AI> cd rag_systems/rag_pro
(special-subject-ai) PS C:\Users\Admin\Desktop\Special_Subject_AI\rag_systems\rag_pro> uv run rag_query.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš€ RAG PRO V2 - QUERY ONLY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ğŸ“Š Embedding: BAAI/bge-m3 (CPU)
   ğŸ¯ Reranker:  BAAI/bge-reranker-v2-m3 (CPU)
   ğŸ¤– LLM:       Llama 3.1 8B (GPU)
   âš¡ Chunking:  Semantic (800-1500 words)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”„ Loading LLM (GPU priority)...
   ğŸ“¥ Loading Llama 3.1 8B...
Loading model...
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:13<00:00,  3.43s/it]
Model loaded!
   âœ… Llama 3.1 8B loaded (GPU)

ğŸ”„ Loading index from disk...
   ğŸ“¦ Loaded index: 88 chunks
   âœ… Loaded 88 chunks

ğŸ”„ Loading embedding & reranker (CPU)...
   ğŸ“¥ Loading BAAI/bge-m3...
   âœ… Embedding model loaded (CPU)
   ğŸ“¥ Loading BAAI/bge-reranker-v2-m3...
   âœ… Reranker loaded (CUDA)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š DATABASE STATS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   Total files: 1
   Total chunks: 88
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ’¬ INTERACTIVE MODE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
GÃµ cÃ¢u há»i. 'exit' Ä‘á»ƒ thoÃ¡t, 'stats' Ä‘á»ƒ xem thá»‘ng kÃª.
------------------------------------------------------------

ğŸ§‘ Báº¡n: NLP lÃ  gÃ¬

ğŸ¤– Äang xá»­ lÃ½...
   ğŸ” Searching...
   ğŸ“„ Found 15 chunks
   ğŸ¯ Reranking to top 2...
   âœ… Selected 2 best chunks
   ğŸ¤– Generating answer...
   âš ï¸  Chunk 1 truncated to fit 1200 token limit
   âœ… Context: 2 chunks, 1200 tokens (limit: 1200)
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.
   â±ï¸ Total: 83.1s

ğŸ“ Tráº£ lá»i:
NLP lÃ  má»™t trong nhá»¯ng lÄ©nh vá»±c cá»‘t yáº¿u cá»§a trÃ­ tuá»‡ nhÃ¢n táº¡o (AI).

(Tá»« Ä‘oáº¡n 1: "Naturallanguage processing (NLP) lÃ  má»™t trong cÃ¡c cÆ¡ sá»Ÿ háº¡ táº§ng cá»§a trÃ­ tuá»‡ nhÃ¢n táº¡o (AI)")

ğŸ§‘ Báº¡n: NLP viáº¿t táº¯t cá»§a tá»« nÃ o

ğŸ¤– Äang xá»­ lÃ½...
   ğŸ” Searching...
   ğŸ“„ Found 15 chunks
   ğŸ¯ Reranking to top 2...
   âœ… Selected 2 best chunks
   ğŸ¤– Generating answer...
   âš ï¸  Chunk 1 truncated to fit 1200 token limit
   âœ… Context: 2 chunks, 1200 tokens (limit: 1200)
Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.
   â±ï¸ Total: 91.0s

ğŸ“ Tráº£ lá»i:
TÃ´i sá»­ dá»¥ng pháº§n "Naturallanguageprocessing (NLP) lÃ  má»™t trong cÃ¡c core subfield cá»§a artificial intelligence (AI)" Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i.

NLP viáº¿t táº¯t cá»§a tá»« "Natural Language Processing".

ğŸ§‘ Báº¡n: NLP Ä‘Ã³ng vai trÃ² gÃ¬ trong AI

ğŸ¤– Äang xá»­ lÃ½...
   ğŸ” Searching...
   ğŸ“„ Found 15 chunks
   ğŸ¯ Reranking to top 2...
   âœ… Selected 2 best chunks
   ğŸ¤– Generating answer...
   âš ï¸  Chunk 1 truncated to fit 1200 token limit
   âœ… Context: 2 chunks, 1200 tokens (limit: 1200)
Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.
   â±ï¸ Total: 860.5s

ğŸ“ Tráº£ lá»i:
TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin nÃ y trong tÃ i liá»‡u.

ğŸ§‘ Báº¡n: kkk

ğŸ¤– Äang xá»­ lÃ½...
   ğŸ” Searching...
   ğŸ“„ Found 15 chunks
   ğŸ¯ Reranking to top 2...
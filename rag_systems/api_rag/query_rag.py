"""
Query RAG - Script há»i Ä‘Ã¡p nhanh (load tá»« database Ä‘Ã£ index)
KhÃ´ng cáº§n parse láº¡i tÃ i liá»‡u, chá»‰ load vÃ  query

Cháº¡y: uv run query_rag.py
Hoáº·c: uv run query_rag.py "cÃ¢u há»i cá»§a báº¡n"
"""

import asyncio
import argparse
import os

# Import RAGAnything
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.utils import EmbeddingFunc

# Import config
from rag_config import (
    RAG_STORAGE, EMBEDDING_MODEL_NAME, EMBEDDING_DIM,
    EMBEDDING_MAX_TOKENS, LLM_MAX_NEW_TOKENS, LLM_TEMPERATURE,
    RAG_CONFIG
)


# ======================== MODELS SETUP (nháº¹ hÆ¡n indexer) ========================
def setup_models():
    """Load vÃ  setup cÃ¡c models (embedding, LLM) - khÃ´ng cáº§n MinerU parser"""
    print("ğŸ”„ Loading models...")
    
    # Import Llama model
    try:
        from Llama_3_1_8B_Instruct_v2 import generate_response
        print("   âœ… Llama 3.1 8B loaded")
    except ImportError as e:
        print(f"   âŒ KhÃ´ng thá»ƒ load Llama model: {e}")
        raise
    
    # Import sentence_transformers
    try:
        from sentence_transformers import SentenceTransformer
    except ImportError:
        print("   âŒ ChÆ°a cÃ i sentence-transformers")
        raise
    
    # Load embedding model
    print(f"   Loading embedding: {EMBEDDING_MODEL_NAME}...")
    embedder = SentenceTransformer(EMBEDDING_MODEL_NAME)
    print("   âœ… Embedding model loaded")
    
    # Create async embedding function
    async def embedding_func(texts):
        return embedder.encode(texts)
    
    embedding = EmbeddingFunc(
        embedding_dim=EMBEDDING_DIM,
        max_token_size=EMBEDDING_MAX_TOKENS,
        func=embedding_func
    )
    
    # Create async LLM function
    async def llm_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        chat_history = history_messages if history_messages else []
        response = generate_response(
            user_input=prompt,
            history=chat_history,
            system_prompt=system_prompt,
            max_new_tokens=LLM_MAX_NEW_TOKENS,
            temperature=LLM_TEMPERATURE
        )
        return response
    
    return embedding, llm_func


# ======================== RAG QUERY ========================
class RAGQuerier:
    """Lightweight RAG querier - chá»‰ load database vÃ  query"""
    
    def __init__(self):
        self.rag = None
        self.initialized = False
    
    async def initialize(self):
        """Initialize RAG tá»« existing storage"""
        if self.initialized:
            return
        
        # Check if database exists
        if not os.path.exists(RAG_STORAGE):
            raise FileNotFoundError(
                f"âŒ Database khÃ´ng tá»“n táº¡i: {RAG_STORAGE}\n"
                f"   Cháº¡y 'uv run index_docs.py' Ä‘á»ƒ index tÃ i liá»‡u trÆ°á»›c!"
            )
        
        # Check for indexed data
        vdb_file = os.path.join(RAG_STORAGE, "vdb_chunks.json")
        if not os.path.exists(vdb_file):
            raise FileNotFoundError(
                f"âŒ Database rá»—ng, chÆ°a cÃ³ dá»¯ liá»‡u index.\n"
                f"   Cháº¡y 'uv run index_docs.py' Ä‘á»ƒ index tÃ i liá»‡u!"
            )
        
        # Setup models
        embedding, llm_func = setup_models()
        
        # Initialize RAG (sáº½ tá»± Ä‘á»™ng load existing data)
        print("\nğŸ”§ Loading RAG database...")
        config = RAGAnythingConfig(**RAG_CONFIG)
        self.rag = RAGAnything(
            config=config,
            llm_model_func=llm_func,
            embedding_func=embedding,
        )
        
        print(f"âœ… RAG loaded tá»« {RAG_STORAGE}")
        self.initialized = True
    
    async def query(self, question: str, mode: str = "hybrid") -> str:
        """Query RAG vá»›i cÃ¢u há»i"""
        if not self.initialized:
            await self.initialize()
        
        try:
            result = await self.rag.aquery(question, mode=mode)
            return result
        except Exception as e:
            return f"âŒ Lá»—i query: {str(e)}"


# ======================== INTERACTIVE MODE ========================
async def interactive_mode(querier: RAGQuerier):
    """Cháº¿ Ä‘á»™ há»i Ä‘Ã¡p tÆ°Æ¡ng tÃ¡c"""
    print("\n" + "=" * 60)
    print("ğŸ’¬ CHáº¾ Äá»˜ Há»I ÄÃP TÆ¯Æ NG TÃC")
    print("=" * 60)
    print("Nháº­p cÃ¢u há»i vÃ  nháº¥n Enter. GÃµ 'exit' Ä‘á»ƒ thoÃ¡t.")
    print("GÃµ 'mode:hybrid', 'mode:local', 'mode:global' Ä‘á»ƒ Ä‘á»•i cháº¿ Ä‘á»™ query.")
    print("-" * 60)
    
    current_mode = "hybrid"
    
    while True:
        try:
            user_input = input(f"\nğŸ§‘ [{current_mode}] Báº¡n: ").strip()
            
            # Check exit
            if user_input.lower() in ["exit", "quit", "q", "thoÃ¡t"]:
                print("ğŸ‘‹ Táº¡m biá»‡t!")
                break
            
            # Check empty
            if not user_input:
                continue
            
            # Check mode change
            if user_input.startswith("mode:"):
                new_mode = user_input.split(":")[1].strip()
                if new_mode in ["hybrid", "local", "global", "naive"]:
                    current_mode = new_mode
                    print(f"âœ… Äá»•i sang cháº¿ Ä‘á»™: {current_mode}")
                else:
                    print("âŒ Mode khÃ´ng há»£p lá»‡. CÃ¡c mode: hybrid, local, global, naive")
                continue
            
            # Query
            print("ğŸ¤– Äang xá»­ lÃ½...")
            result = await querier.query(user_input, mode=current_mode)
            print(f"\nğŸ¤– AI:\n{result}")
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Táº¡m biá»‡t!")
            break
        except EOFError:
            print("\nğŸ‘‹ Táº¡m biá»‡t!")
            break
        except Exception as e:
            print(f"âŒ Lá»—i: {str(e)}")


# ======================== SINGLE QUERY MODE ========================
async def single_query(question: str, mode: str = "hybrid"):
    """Cháº¡y má»™t query duy nháº¥t vÃ  thoÃ¡t"""
    print("=" * 60)
    print("ğŸ” RAG QUERY")
    print("=" * 60)
    
    querier = RAGQuerier()
    await querier.initialize()
    
    print(f"\nâ“ CÃ¢u há»i: {question}")
    print(f"ğŸ“Œ Mode: {mode}")
    print("-" * 60)
    
    result = await querier.query(question, mode=mode)
    
    print(f"\nğŸ“ Káº¿t quáº£:\n{result}")


# ======================== MAIN ========================
async def main_async(args):
    """Main async entry point"""
    if args.question:
        # Single query mode
        await single_query(args.question, mode=args.mode)
    else:
        # Interactive mode
        print("=" * 60)
        print("ğŸš€ RAG QUERIER")
        print("=" * 60)
        
        querier = RAGQuerier()
        await querier.initialize()
        await interactive_mode(querier)


def main():
    parser = argparse.ArgumentParser(description="Query RAG database")
    parser.add_argument(
        'question',
        nargs='?',
        default=None,
        help='CÃ¢u há»i Ä‘á»ƒ query (náº¿u khÃ´ng cÃ³ sáº½ vÃ o cháº¿ Ä‘á»™ interactive)'
    )
    parser.add_argument(
        '--mode', '-m',
        default='hybrid',
        choices=['hybrid', 'local', 'global', 'naive'],
        help='Cháº¿ Ä‘á»™ query (default: hybrid)'
    )
    args = parser.parse_args()
    
    asyncio.run(main_async(args))


if __name__ == "__main__":
    main()

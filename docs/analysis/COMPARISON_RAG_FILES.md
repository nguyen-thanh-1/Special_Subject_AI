# So sÃ¡nh chi tiáº¿t: pageindex_llama_rag.py vs pageindex_llama_rag_simple.py

## ğŸ” Tá»•ng quan

Cáº£ 2 file Ä‘á»u lÃ  há»‡ thá»‘ng PageIndex RAG vá»›i Llama 3.1 8B, nhÆ°ng cÃ³ **sá»± khÃ¡c biá»‡t quan trá»ng** vá» cÃ¡ch load model.

## ğŸ“Š Báº£ng so sÃ¡nh

| Äáº·c Ä‘iá»ƒm | `pageindex_llama_rag.py` | `pageindex_llama_rag_simple.py` |
|----------|--------------------------|----------------------------------|
| **CÃ¡ch load model** | Load trá»±c tiáº¿p tá»« HuggingFace | Import tá»« file `Llama_3_1_8B_Instruct_v2.py` |
| **Dependencies** | `torch`, `transformers`, `bitsandbytes` | Phá»¥ thuá»™c vÃ o file `Llama_3_1_8B_Instruct_v2.py` |
| **Quantization** | 4-bit (BitsAndBytesConfig) + Fallback FP16 | Phá»¥ thuá»™c vÃ o file Ä‘Æ°á»£c import |
| **Standalone** | âœ… Äá»™c láº­p hoÃ n toÃ n | âŒ Cáº§n file `Llama_3_1_8B_Instruct_v2.py` |
| **LLM Wrapper** | Class `LlamaLLM` riÃªng | Sá»­ dá»¥ng `llama.generate_response()` |
| **PageIndex** | Import tá»« `pageindex_core.py` | Tá»± implement class `LocalPageIndex` |
| **Sá»‘ dÃ²ng code** | 289 dÃ²ng | 312 dÃ²ng |
| **PhÃ¹ há»£p cho** | Production, deployment | Testing, development |

## ğŸ”‘ Äiá»ƒm khÃ¡c biá»‡t chÃ­nh

### 1. CÃ¡ch load Model

#### `pageindex_llama_rag.py` (STANDARD)
```python
class LlamaLLM:
    def __init__(self, model_id="meta-llama/Llama-3.1-8B-Instruct"):
        self.model_id = model_id
        self.model = None
        self.tokenizer = None
        self.load_model()  # Load trá»±c tiáº¿p
    
    def load_model(self):
        # Cáº¥u hÃ¬nh quantization 4-bit
        bnb_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_compute_dtype=torch.bfloat16,
            bnb_4bit_use_double_quant=True,
        )
        
        # Load tokenizer vÃ  model
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_id)
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_id,
            device_map="auto",
            quantization_config=bnb_config,
        )
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Äá»™c láº­p, khÃ´ng phá»¥ thuá»™c file khÃ¡c
- âœ… Control Ä‘áº§y Ä‘á»§ viá»‡c load model
- âœ… CÃ³ fallback tá»± Ä‘á»™ng sang FP16 náº¿u 4-bit lá»—i
- âœ… PhÃ¹ há»£p production

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Máº¥t thá»i gian load model (1-2 phÃºt)
- âŒ Cáº§n cáº¥u hÃ¬nh quantization

---

#### `pageindex_llama_rag_simple.py` (SIMPLE)
```python
def import_llm_module():
    """Import module Llama tá»« file cÃ³ sáºµn"""
    module_path = Path(__file__).parent / "Llama_3_1_8B_Instruct_v2.py"
    
    spec = importlib.util.spec_from_file_location("llama_module", module_path)
    llama_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(llama_module)
    
    return llama_module

# Load LLM
llama = import_llm_module()

# Sá»­ dá»¥ng
response = llama.generate_response(
    user_input=user_prompt,
    history=history,
    max_new_tokens=max_new_tokens,
    temperature=temperature
)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Nhanh hÆ¡n náº¿u model Ä‘Ã£ Ä‘Æ°á»£c load trong file khÃ¡c
- âœ… TÃ¡i sá»­ dá»¥ng code cÃ³ sáºµn
- âœ… ÄÆ¡n giáº£n, dá»… test

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Phá»¥ thuá»™c vÃ o file `Llama_3_1_8B_Instruct_v2.py`
- âŒ KhÃ´ng control Ä‘Æ°á»£c cÃ¡ch load model
- âŒ Váº«n pháº£i load model láº§n Ä‘áº§u (khÃ´ng tiáº¿t kiá»‡m thá»i gian)

### 2. PageIndex Implementation

#### `pageindex_llama_rag.py`
```python
# Import tá»« module riÃªng
from pageindex_core import LocalPageIndex, format_context_for_prompt

# Sá»­ dá»¥ng
self.page_index = LocalPageIndex(documents_dir)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Code gá»n gÃ ng, modular
- âœ… TÃ¡i sá»­ dá»¥ng Ä‘Æ°á»£c cho nhiá»u file
- âœ… Dá»… maintain

---

#### `pageindex_llama_rag_simple.py`
```python
# Tá»± implement class LocalPageIndex trong file
class LocalPageIndex:
    def __init__(self, documents_dir="./courses"):
        self.documents_dir = Path(documents_dir)
        self.index = {}
        self.documents = {}
    
    # ... toÃ n bá»™ implementation
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Standalone, khÃ´ng cáº§n import
- âœ… Dá»… Ä‘á»c toÃ n bá»™ logic trong 1 file

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Code dÃ i hÆ¡n (duplicate code)
- âŒ KhÃ³ maintain khi cÃ³ nhiá»u file

### 3. LLM Interface

#### `pageindex_llama_rag.py`
```python
class LlamaLLM:
    def chat(self, messages, max_new_tokens=512, temperature=0.2):
        """Chat vá»›i history"""
        prompt = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        return self.generate(prompt, max_new_tokens, temperature)

# Sá»­ dá»¥ng
response = self.llm.chat(messages, max_new_tokens, temperature)
```

---

#### `pageindex_llama_rag_simple.py`
```python
# Sá»­ dá»¥ng function tá»« file Ä‘Æ°á»£c import
response = llama.generate_response(
    user_input=user_prompt,
    history=history,
    max_new_tokens=max_new_tokens,
    temperature=temperature
)
```

## ğŸ¯ Khi nÃ o dÃ¹ng file nÃ o?

### DÃ¹ng `pageindex_llama_rag.py` khi:
âœ… **Production deployment**  
âœ… Muá»‘n control Ä‘áº§y Ä‘á»§ viá»‡c load model  
âœ… Cáº§n quantization 4-bit Ä‘á»ƒ tiáº¿t kiá»‡m VRAM  
âœ… Muá»‘n code modular, dá»… maintain  
âœ… KhÃ´ng muá»‘n phá»¥ thuá»™c file khÃ¡c  

**VÃ­ dá»¥:**
```bash
# Cháº¡y standalone
python pageindex_llama_rag.py

# Hoáº·c
uv run pageindex_llama_rag.py
```

---

### DÃ¹ng `pageindex_llama_rag_simple.py` khi:
âœ… **Testing vÃ  development**  
âœ… ÄÃ£ cÃ³ file `Llama_3_1_8B_Instruct_v2.py` working  
âœ… Muá»‘n test PageIndex logic nhanh  
âœ… KhÃ´ng quan tÃ¢m cÃ¡ch load model  

**VÃ­ dá»¥:**
```bash
# Cáº§n cÃ³ file Llama_3_1_8B_Instruct_v2.py
python pageindex_llama_rag_simple.py
```

## ğŸ“ Code Structure Comparison

### `pageindex_llama_rag.py`
```
pageindex_llama_rag.py (289 dÃ²ng)
â”œâ”€â”€ Import statements
â”‚   â”œâ”€â”€ torch, transformers
â”‚   â””â”€â”€ pageindex_core (LocalPageIndex, format_context_for_prompt)
â”œâ”€â”€ LlamaLLM class (88 dÃ²ng)
â”‚   â”œâ”€â”€ __init__()
â”‚   â”œâ”€â”€ load_model() - vá»›i quantization + fallback
â”‚   â”œâ”€â”€ generate()
â”‚   â””â”€â”€ chat()
â”œâ”€â”€ PageIndexRAG class (86 dÃ²ng)
â”‚   â”œâ”€â”€ __init__() - khá»Ÿi táº¡o PageIndex + LLM
â”‚   â”œâ”€â”€ query()
â”‚   â”œâ”€â”€ rebuild_index()
â”‚   â””â”€â”€ get_statistics()
â””â”€â”€ main() - Interactive interface
```

### `pageindex_llama_rag_simple.py`
```
pageindex_llama_rag_simple.py (312 dÃ²ng)
â”œâ”€â”€ Import statements
â”‚   â””â”€â”€ importlib.util
â”œâ”€â”€ import_llm_module() - Import tá»« file
â”œâ”€â”€ LocalPageIndex class (145 dÃ²ng) - Tá»± implement
â”‚   â”œâ”€â”€ __init__()
â”‚   â”œâ”€â”€ build_index()
â”‚   â”œâ”€â”€ _index_document()
â”‚   â”œâ”€â”€ search()
â”‚   â”œâ”€â”€ _calculate_relevance()
â”‚   â””â”€â”€ get_context()
â”œâ”€â”€ PageIndexRAG class (75 dÃ²ng)
â”‚   â”œâ”€â”€ __init__()
â”‚   â”œâ”€â”€ query() - dÃ¹ng llama.generate_response()
â”‚   â””â”€â”€ rebuild_index()
â””â”€â”€ main() - Interactive interface
```

## ğŸ’¡ Khuyáº¿n nghá»‹

### Cho ngÆ°á»i má»›i báº¯t Ä‘áº§u
â†’ DÃ¹ng **`pageindex_llama_rag.py`**
- ÄÆ¡n giáº£n hÆ¡n, Ã­t phá»¥ thuá»™c
- CÃ³ error handling tá»‘t hÆ¡n
- Documentation rÃµ rÃ ng

### Cho developer cÃ³ kinh nghiá»‡m
â†’ DÃ¹ng **`pageindex_llama_rag.py`** cho production
â†’ DÃ¹ng **`pageindex_llama_rag_simple.py`** cho testing

### Cho multi-format (PDF, DOCX)
â†’ DÃ¹ng **`pageindex_multiformat.py`** â­
- Há»— trá»£ nhiá»u format nháº¥t
- Architecture tá»‘t nháº¥t
- Recommended!

## ğŸ”„ Migration Path

Náº¿u báº¡n Ä‘ang dÃ¹ng `pageindex_llama_rag_simple.py` vÃ  muá»‘n chuyá»ƒn sang `pageindex_llama_rag.py`:

```bash
# KhÃ´ng cáº§n thay Ä‘á»•i gÃ¬
# Chá»‰ cáº§n cháº¡y file má»›i
python pageindex_llama_rag.py

# Model sáº½ Ä‘Æ°á»£c load tá»± Ä‘á»™ng
# Táº¥t cáº£ chá»©c nÄƒng giá»‘ng nhau
```

## ğŸ“Š Performance Comparison

| Metric | Standard | Simple |
|--------|----------|--------|
| Startup time | ~60-120s (load model) | ~60-120s (load model) |
| Memory usage | ~6GB VRAM (4-bit) | Phá»¥ thuá»™c file import |
| Query speed | Giá»‘ng nhau | Giá»‘ng nhau |
| Code maintainability | â­â­â­â­â­ | â­â­â­ |
| Flexibility | â­â­â­â­â­ | â­â­â­ |

## âœ… Káº¿t luáº­n

**TL;DR:**
- `pageindex_llama_rag.py` = **Production-ready**, standalone, modular
- `pageindex_llama_rag_simple.py` = **Testing**, phá»¥ thuá»™c file khÃ¡c, monolithic

**Khuyáº¿n nghá»‹:** DÃ¹ng `pageindex_llama_rag.py` hoáº·c `pageindex_multiformat.py` cho háº§u háº¿t use cases.

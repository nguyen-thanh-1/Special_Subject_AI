# Fix LLM CPU Issue

## ğŸ”´ Váº¥n Ä‘á»

Khi cháº¡y `rag_query.py`, LLM cháº¡y trÃªn CPU thay vÃ¬ GPU â†’ **Ráº¤T CHáº¬M**

## ğŸ” NguyÃªn nhÃ¢n

**Thá»© tá»± load models khÃ´ng Ä‘Ãºng:**

```python
# SAI - Load theo thá»© tá»± nÃ y:
get_embedder()   # Load lÃªn trÆ°á»›c
get_reranker()   # Load lÃªn trÆ°á»›c  
get_llm()        # Load sau â†’ Bá»‹ Ä‘áº©y xuá»‘ng CPU!
```

**Váº¥n Ä‘á»:**
- Embedding/Reranker load trÆ°á»›c, chiáº¿m má»™t pháº§n VRAM
- LLM load sau, khÃ´ng Ä‘á»§ VRAM â†’ PyTorch tá»± Ä‘á»™ng Ä‘áº©y xuá»‘ng CPU
- Káº¿t quáº£: LLM cháº¡y CPU (cháº­m 10-20x)

---

## âœ… Giáº£i phÃ¡p

**Load LLM TRÆ¯á»šC Ä‘á»ƒ Ä‘áº£m báº£o nÃ³ Ä‘Æ°á»£c Æ°u tiÃªn GPU:**

```python
# ÄÃšNG - Load theo thá»© tá»± nÃ y:
get_llm()        # Load TRÆ¯á»šC â†’ Chiáº¿m GPU
get_embedder()   # Load sau â†’ CPU (nhÆ° Ä‘Ã£ config)
get_reranker()   # Load sau â†’ CPU (nhÆ° Ä‘Ã£ config)
```

**LÃ½ do:**
- LLM load trÆ°á»›c â†’ Chiáº¿m 12GB VRAM trÃªn GPU
- Embedding/Reranker load sau â†’ Tá»± Ä‘á»™ng cháº¡y CPU (Ä‘Ã£ config sáºµn)
- Káº¿t quáº£: LLM cháº¡y GPU (nhanh)

---

## ğŸ”§ Code Ä‘Ã£ sá»­a

### File: `rag_query.py`

**TrÆ°á»›c:**
```python
def main():
    # Initialize
    rag = RAGQuery()
    
    # Load models
    get_embedder()   # âŒ Load trÆ°á»›c
    get_reranker()   # âŒ Load trÆ°á»›c
    get_llm()        # âŒ Load sau â†’ CPU
```

**Sau:**
```python
def main():
    # CRITICAL: Load LLM FIRST to ensure it gets GPU
    print("\nğŸ”„ Loading LLM (GPU priority)...")
    get_llm()        # âœ… Load TRÆ¯á»šC â†’ GPU
    
    # Initialize
    rag = RAGQuery()
    
    # Load embedding and reranker AFTER LLM (on CPU)
    print("\nğŸ”„ Loading embedding & reranker (CPU)...")
    get_embedder()   # âœ… Load sau â†’ CPU
    get_reranker()   # âœ… Load sau â†’ CPU
```

---

## ğŸ“Š Káº¿t quáº£

### TrÆ°á»›c (LLM CPU):
```
ğŸ§‘ Báº¡n: What is NLP?

ğŸ¤– Äang xá»­ lÃ½...
   ğŸ” Searching... (0.5s)
   ğŸ¯ Reranking... (1.5s)
   ğŸ¤– Generating answer... (60s) â† CPU Ráº¤T CHáº¬M!
   â±ï¸ Total: 62s
```

### Sau (LLM GPU):
```
ğŸ§‘ Báº¡n: What is NLP?

ğŸ¤– Äang xá»­ lÃ½...
   ğŸ” Searching... (0.5s)
   ğŸ¯ Reranking... (1.5s)
   ğŸ¤– Generating answer... (5s) â† GPU NHANH!
   â±ï¸ Total: 7s
```

**Cáº£i thiá»‡n: 62s â†’ 7s (9x nhanh hÆ¡n!)**

---

## ğŸš€ CÃ¡ch cháº¡y láº¡i

```bash
# Stop chÆ°Æ¡ng trÃ¬nh hiá»‡n táº¡i (Ctrl+C)

# Cháº¡y láº¡i vá»›i fix má»›i
uv run rag_query.py
```

**Output má»›i:**
```
ğŸ”„ Loading LLM (GPU priority)...
Loading model...
Model loaded!
   âœ… Llama 3.1 8B loaded

ğŸ”„ Loading index from disk...
   âœ… Loaded 88 chunks

ğŸ”„ Loading embedding & reranker (CPU)...
   âœ… Embedding model loaded (CPU)
   âœ… Reranker loaded (CPU)
```

---

## ğŸ’¡ NguyÃªn táº¯c quan trá»ng

**Khi cÃ³ nhiá»u models:**
1. **Load model lá»›n nháº¥t TRÆ¯á»šC** (Ä‘á»ƒ chiáº¿m GPU)
2. **Load models nhá» SAU** (Ä‘á»ƒ cháº¡y CPU)

**Trong trÆ°á»ng há»£p nÃ y:**
1. LLM (12GB) â†’ Load TRÆ¯á»šC â†’ GPU
2. Embedding (3GB) â†’ Load SAU â†’ CPU
3. Reranker (2GB) â†’ Load SAU â†’ CPU

---

## âœ… ÄÃ£ fix!

BÃ¢y giá» LLM sáº½ cháº¡y trÃªn GPU vÃ  query sáº½ nhanh hÆ¡n nhiá»u! ğŸš€

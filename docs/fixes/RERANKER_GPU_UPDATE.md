# Reranker GPU Update

## âœ… ÄÃ£ sá»­a: Reranker cháº¡y GPU

### ğŸ”§ Thay Ä‘á»•i:

**File: `rag_pro_v2.py`**

**TrÆ°á»›c:**
```python
# Force CPU to avoid CUDA OOM (Llama already on GPU)
_reranker = CrossEncoder(RERANKER_MODEL, device='cpu')
```

**Sau:**
```python
# Use GPU for faster reranking (query-only mode)
device = 'cuda' if torch.cuda.is_available() else 'cpu'
_reranker = CrossEncoder(RERANKER_MODEL, device=device)
```

---

## ğŸ“Š Device Allocation (Query Mode)

### Má»›i:
```
Embedding (CPU):  0GB VRAM  â† Chá»‰ embed 1 query (0.05s)
Reranker (GPU):   2GB VRAM  â† Rerank 50 chunks (0.5s)
LLM (GPU):       12GB VRAM  â† Generate answer (5s)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:           14GB VRAM  âœ… (Safe cho GPU 16GB)
```

### CÅ©:
```
Embedding (CPU):  0GB VRAM
Reranker (CPU):   0GB VRAM  â† Cháº­m (1.5s)
LLM (GPU):       12GB VRAM
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:           12GB VRAM
```

---

## â±ï¸ Performance Improvement

### Query Pipeline:

**TrÆ°á»›c (Reranker CPU):**
```
ğŸ” Query: "NLP lÃ  gÃ¬?"
   Embed query (CPU):     0.05s
   FAISS search:          0.5s
   Rerank (CPU):          1.5s  â† Cháº­m
   LLM generate (GPU):    5s
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Total:                 7.05s
```

**Sau (Reranker GPU):**
```
ğŸ” Query: "NLP lÃ  gÃ¬?"
   Embed query (CPU):     0.05s
   FAISS search:          0.5s
   Rerank (GPU):          0.5s  â† Nhanh hÆ¡n 3x!
   LLM generate (GPU):    5s
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Total:                 6.05s  âœ… Nhanh hÆ¡n 1s!
```

**Cáº£i thiá»‡n: 7.05s â†’ 6.05s (14% faster)**

---

## ğŸš€ CÃ¡ch cháº¡y láº¡i

```bash
# Stop chÆ°Æ¡ng trÃ¬nh hiá»‡n táº¡i (Ctrl+C)

# Cháº¡y láº¡i
uv run rag_query.py
```

**Output má»›i:**
```
ğŸš€ RAG PRO V2 - QUERY ONLY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ğŸ“Š Embedding: BAAI/bge-m3 (CPU)
   ğŸ¯ Reranker:  BAAI/bge-reranker-v2-m3 (GPU)  â† GPU!
   ğŸ¤– LLM:       Llama 3.1 8B (GPU)

ğŸ”„ Loading LLM (GPU priority)...
   âœ… Llama 3.1 8B loaded

ğŸ”„ Loading embedding & reranker (CPU)...
   ğŸ“¥ Loading BAAI/bge-m3...
   âœ… Embedding model loaded (CPU)
   ğŸ“¥ Loading BAAI/bge-reranker-v2-m3...
   âœ… Reranker loaded (CUDA)  â† GPU!
```

---

## ğŸ’¡ Táº¡i sao bÃ¢y giá» má»›i chuyá»ƒn GPU?

### TrÆ°á»›c (All-in-one):
- Index + Query trong 1 script
- LLM load sáºµn khi index (chiáº¿m 12GB)
- Reranker pháº£i CPU (trÃ¡nh OOM)

### BÃ¢y giá» (TÃ¡ch riÃªng):
- Query riÃªng, khÃ´ng index
- LLM load Ä‘Ãºng lÃºc (lazy loading)
- Reranker cÃ³ thá»ƒ GPU (váº«n cÃ²n 4GB VRAM)

---

## âœ… Káº¿t quáº£

**Lá»£i Ã­ch:**
- âš¡ Nhanh hÆ¡n 1s (7s â†’ 6s)
- ğŸ’¾ Váº«n an toÃ n (14GB < 16GB)
- ğŸ¯ Tá»‘i Æ°u hÆ¡n (dÃ¹ng háº¿t GPU)

**Trade-off:**
- VRAM tÄƒng 2GB (12GB â†’ 14GB)
- Váº«n an toÃ n vá»›i GPU 16GB

**BÃ¢y giá» hÃ£y cháº¡y láº¡i vÃ  test!** ğŸš€
